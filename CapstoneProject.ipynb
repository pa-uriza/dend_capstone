{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# I94 DataWarehouse - Data Engineering Capstone Project\n",
    "\n",
    "## Project Summary\n",
    "The aim of this project is to implement the desing and construction of a data warehouse from I94 dataset. Through this, data will be available to perform analysis and run models to support decision making. By combining different data sources, the idea is to enrich current knowledge of the immigration process to make data actionable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Implementation\n",
    "\n",
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### 1.1 Scope \n",
    "In this project, three data sources are joined to understand the immigration process better. The datasets used will be I94 Immigration Data, U.S. City Demographics Data, and Airport Code Table. The Department of Homeland Security (DHS) issues the I94 form to all persons in the U.S. except citizens to control the entrance to the country and for security-related reasons. Therefore, being able to assess and understand the characteristics and analyze the immigration process would benefit the DHS and other organizations. Joining information from the DHS and airports information could enhance the analysis and help the understanding of who travels to the U.S. and which are the most important airports for immigration. Additionally, comparing this with demographic data would allow us to analyze the statistics of the population and how they could affect immigration patterns.\n",
    "\n",
    "Some of the tools used for this project are AWS S3 (for data storage) and pandas and pyspark (for data exploration and processing).\n",
    "\n",
    "#### 1.2 Describe and Gather Data \n",
    "\n",
    "Following are the data sources used for this project:\n",
    "\n",
    "|           Dataset          |                                                                                       Description                                                                                       |                                                                                                                                                    Source                                                                                                                                                    | Format |\n",
    "|:--------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------:|\n",
    "| I94 Immigration Data       | Data from the US National Tourism and Trade Office. Contains international visitor<br>information including demographics and trip specific information as arrival and<br>departure date | [Link](https://classroom.udacity.com/nanodegrees/nd027/parts/dce8f032-1b05-4d57-a30b-d6e41f01e800/modules/c46c3dad-e89f-44a2-9599-b758bfa3a3ba/lessons/b18ab222-552a-432b-aae8-7c52c5e72d37/concepts/7b7f4199-d02b-4684-8e8c-0a58318c62ee#:~:text=in%20the%20workspace.-,This,-is%20where%20the)             | SAS    |\n",
    "| U.S. City Demographic Data | Contains information about the demographics of US cities                                                                                                                                | [Link](https://classroom.udacity.com/nanodegrees/nd027/parts/dce8f032-1b05-4d57-a30b-d6e41f01e800/modules/c46c3dad-e89f-44a2-9599-b758bfa3a3ba/lessons/b18ab222-552a-432b-aae8-7c52c5e72d37/concepts/7b7f4199-d02b-4684-8e8c-0a58318c62ee#:~:text=OpenSoft.%20You%20can%20read%20more%20about%20it-,here,-.) | CSV    |\n",
    "| Airport Code Table         | Contains airport information including location (coordinates and city) and height<br>in feet.                                                                                           | [Link](https://classroom.udacity.com/nanodegrees/nd027/parts/dce8f032-1b05-4d57-a30b-d6e41f01e800/modules/c46c3dad-e89f-44a2-9599-b758bfa3a3ba/lessons/b18ab222-552a-432b-aae8-7c52c5e72d37/concepts/7b7f4199-d02b-4684-8e8c-0a58318c62ee#:~:text=It%20comes%20from-,here,-.)                                | CSV    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "#### 2.1 Explore the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  ...  entdepu  matflag  biryear   dtaddto  gender insnum  \\\n",
       "0      1.0      HI  ...      NaN        M   1955.0  07202016       F    NaN   \n",
       "1      1.0      TX  ...      NaN        M   1990.0  10222016       M    NaN   \n",
       "2      1.0      FL  ...      NaN        M   1940.0  07052016       M    NaN   \n",
       "3      1.0      CA  ...      NaN        M   1991.0  10272016       M    NaN   \n",
       "4      3.0      NY  ...      NaN        M   1997.0  07042016       F    NaN   \n",
       "\n",
       "  airline        admnum  fltno  visatype  \n",
       "0      JL  5.658267e+10  00782        WT  \n",
       "1     *GA  9.436200e+10  XBLNG        B2  \n",
       "2      LH  5.578047e+10  00464        WT  \n",
       "3      QR  9.478970e+10  00739        B2  \n",
       "4     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the i94 dataset\n",
    "df_i94 = pd.read_csv('data/sample/immigration_data_sample.csv')\n",
    "df_i94.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port',\n",
       "       'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa',\n",
       "       'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd',\n",
       "       'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum',\n",
       "       'airline', 'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([209., 582., 112., 297., 111., 577., 245., 135., 131., 116., 438.,\n",
       "       260., 512., 689., 158., 115., 511., 251., 268., 585., 213., 264.,\n",
       "       509., 324., 696., 117., 687., 129., 528., 123., 258., 691., 130.,\n",
       "       107., 103., 694., 276., 206., 368., 575., 586., 120., 514., 124.,\n",
       "       273., 692., 109., 579., 164., 126., 263., 464., 602., 121., 162.,\n",
       "       274., 690., 207., 104., 525., 105., 518., 343., 504., 576., 272.,\n",
       "       108., 127., 140., 526., 603., 332., 513., 516., 218., 296., 204.,\n",
       "       201., 114., 257., 266., 520., 243., 261., 113., 373., 299., 688.,\n",
       "       141., 350., 340.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.i94res.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WT', 'B2', 'CP', 'B1', 'GMT', 'WB', 'F1', 'E2', 'F2', 'M1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.visatype.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.cicid.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i94port\n",
       "NYC    155\n",
       "MIA    111\n",
       "LOS    106\n",
       "SFR     55\n",
       "CHI     45\n",
       "      ... \n",
       "ONT      1\n",
       "OPF      1\n",
       "OTM      1\n",
       "PEM      1\n",
       "X96      1\n",
       "Length: 70, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.groupby(by='i94port').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i94mode\n",
       "1.0    962\n",
       "3.0     26\n",
       "2.0     10\n",
       "9.0      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.groupby(by='i94mode').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visatype\n",
       "WT     443\n",
       "B2     356\n",
       "WB      91\n",
       "B1      61\n",
       "GMT     27\n",
       "F1      10\n",
       "CP       5\n",
       "E2       3\n",
       "F2       3\n",
       "M1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.groupby(by='visatype').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the demographics dataset\n",
    "df_dem = pd.read_csv('data/sample/us-cities-demographics.csv', sep=';')\n",
    "df_dem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
       "       'Total Population', 'Number of Veterans', 'Foreign-born',\n",
       "       'Average Household Size', 'State Code', 'Race', 'Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dem.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hispanic or Latino', 'White', 'Asian',\n",
       "       'Black or African-American', 'American Indian and Alaska Native'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dem['Race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State        Race                             \n",
       "California   White                                137\n",
       "             Hispanic or Latino                   137\n",
       "             Black or African-American            136\n",
       "             Asian                                136\n",
       "             American Indian and Alaska Native    130\n",
       "                                                 ... \n",
       "Hawaii       Asian                                  1\n",
       "             Black or African-American              1\n",
       "             Hispanic or Latino                     1\n",
       "Mississippi  American Indian and Alaska Native      1\n",
       "Hawaii       White                                  1\n",
       "Length: 243, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dem.groupby(by=['State', 'Race']).size().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore airport dataset\n",
    "df_airport = pd.read_csv('data/sample/airport-codes_csv.csv')\n",
    "df_airport.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ident', 'type', 'name', 'elevation_ft', 'continent', 'iso_country',\n",
       "       'iso_region', 'municipality', 'gps_code', 'iata_code', 'local_code',\n",
       "       'coordinates'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'UTK', 'OCA', ..., 'SHE', 'YNJ', 'YKH'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.iata_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iata_code\n",
       "0      80\n",
       "OHE     3\n",
       "PRI     3\n",
       "BCK     2\n",
       "CLG     2\n",
       "       ..\n",
       "HMA     1\n",
       "HLZ     1\n",
       "HLW     1\n",
       "HLV     1\n",
       "ZZV     1\n",
       "Length: 9042, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.groupby(by='iata_code').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heliport', 'small_airport', 'closed', 'seaplane_base',\n",
       "       'balloonport', 'medium_airport', 'large_airport'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Cleaning Steps\n",
    "\n",
    "1. Parse I94_SAS_Labels_Descriptions.SAS file to get country code, country name mapping\n",
    "\n",
    "2. Join `i94cit` and `i94res` field with country name mapping to get country of citizenship and country of residence of immigrants\n",
    "\n",
    "3. Transform `arrdate`, `depdate` in i94 immigration data from SAS time format to datetime object\n",
    "\n",
    "4. Select only fields according to dimensional model and rename them accordingly\n",
    "\n",
    "5. Drop duplicate values from all tables at defined grain level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "This project follows the 4 steps in Kimball's dimensional modeling methodology:\n",
    "1. **Select the business process:** As discussed in the scope of the project, the main objective is to create a Data Warehouse for support decision making regarding the immigration process. Therefore we focused on the immigration process represented in the data gathered using the i94 form. Through this data model we want to uncover relationships and patterns in migration data collected.\n",
    "\n",
    "2. **Declare the grain:** The grain will be each i94 form record which corresponds to an immigrant filling the form for a specific visit to the US.\n",
    "\n",
    "3. **Identify the dimensions:** We defined a `Dim_Demographics` table containing information of the respondent's destination in the US. We also defined a `Dim_Airports` that contain information of the location of different airports around the world. Finally we defined the table `Dim_Traveler` that contains information of the traveler including gender and year of birth among others.\n",
    "\n",
    "4. **Identify the facts:** The fact table `Fact_Traveler`, contain available facts for this granularity corresponds to the respondent's age (a non-additive fact) and an auxiliar `count` field to perform aggregations.\n",
    "\n",
    "The dimensional model is depicted as follows:\n",
    "\n",
    "![dimensional_model](img/dimensional_model.png)\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "Raw data is stored in a S3 source bucket from where it will be extracted and transformed to conform a dimensional model for analytics purposes (report generation, statistical modeling, etc.). Transfored dimensional and fact tables are stored into a S3 destination bucket in parquet format. All transformations are performed using python. Data intensive transformations are leveraged using pyspark.\n",
    "\n",
    "![solution](img/solution_stack.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data\n",
    "\n",
    "#### 4.1 Create the data model\n",
    "\n",
    "To build the data model the follwong `bash` is run which performs the aforementioned ETL process\n",
    "\n",
    "``` bash\n",
    "python etl.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "To ensure the pipeline ran as expected, we included some data quality checks:\n",
    " * Assert data schema of every table\n",
    " * Assert non-empty tables after running ETL data pipeline\n",
    " \n",
    "To run them use the `bash` command\n",
    "\n",
    "``` bash\n",
    "python qa.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary\n",
    "\n",
    "**Dim_Demographics**\n",
    "\n",
    "|Field               |Description                                              |\n",
    "|--------------------|---------------------------------------------------------|\n",
    "| state_code         | Two letter code to identify state                       |\n",
    "| state              | US state name                                           |\n",
    "| race               | Ethnicity                                               |\n",
    "| median_age         | Median age                                              |\n",
    "| male_population    | Male population for certain state, city and ethnicity   |\n",
    "| female_population  | Female population for certain state, city and ethnicity |\n",
    "| total_population   | Total population for certain state, city and ethnicity  |\n",
    "\n",
    "**Dim_Airports**\n",
    "\n",
    "| Field        | Description                                                    |\n",
    "|--------------|----------------------------------------------------------------|\n",
    "| iata_code    | International Air Transport Association airport code           |\n",
    "| type         | Type of airport                                                |\n",
    "| name         | Name of the airport                                            |\n",
    "| elevation_ft | Elevation of the airport in feet                               |\n",
    "| continent    | Continent of the airport                                       |\n",
    "| iso_country  | ISO three-letter code for the country where airport is located |\n",
    "| iso_region   | ISO code for the region where airport is located               |\n",
    "| municipality | City or town where airport is located                          |\n",
    "| coordinates  | Longitude and latitude of the airport                          |\n",
    "\n",
    "**Dim_Traveler**\n",
    "\n",
    "| Field       | Description                                |\n",
    "|-------------|--------------------------------------------|\n",
    "| cicid       | Unique immigration identifier for traveler |\n",
    "| arrdate     | Arival date of the traveler                |\n",
    "| depdate     | Departure date of the traveler             |\n",
    "| year        | Year of arrival                            |\n",
    "| month       | Month of arrival                           |\n",
    "| citizenship | Country of citizenship of the traveler     |\n",
    "| residence   | Country of residence of the traveler       |\n",
    "| reason      | Reason of visiting the US                  |\n",
    "| biryear     | Birth year of the traveler                 |\n",
    "| gender      | Gender of the traveler                     |\n",
    "| visatype    | Visa type                                  |\n",
    "\n",
    "**Fact_Traveler**\n",
    "\n",
    "| Field      | Description                                          |\n",
    "|------------|------------------------------------------------------|\n",
    "| cicid      | Unique immigration identifier for traveler           |\n",
    "| state_code | Two letter code to identify state                    |\n",
    "| iata_code  | International Air Transport Association airport code |\n",
    "| age        | Age of the traveler                                  |\n",
    "| count      | Auxiliar variable to count summarize                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "\n",
    "#### Tools and technologies\n",
    "* AWS Simple Storage Service (S3) for raw and processed data storage. Storage on s3 allow to have high volumes of data at relatively low costs. s3 is a good choice for implementing a datalake containing various format data to get staging tables for data modeling\n",
    "* [`pandas`](https://pandas.pydata.org/) for sample EDA as is one of the most popular packages in data science for data wrangling\n",
    "* [`pyspark`](https://spark.apache.org/docs/latest/api/python/) for ETL process for its great capability of massive data processing\n",
    "\n",
    "#### Update frequency\n",
    "* US Demographics should be updated everytime a new report is available. As census data is costly to get, in most countries it is performed once a few years and estimates updated on a yearly basis. If it is the case data should be updated yearly.\n",
    "\n",
    "* Airport codes table will have a very low update frequency as changes in this information is strange. Principally when new airports are built, some new records will appear. It would be prudent to update in a yearly basis.\n",
    "\n",
    "* Immigration data should be updated every month given that raw data seems ti be reported every month. As the granularity for this analysis comes from this source, it is very important to have the most updated data.\n",
    "\n",
    "* As new data is available, tables should have new inserted rows in contrast to replace existing ones.\n",
    "\n",
    "#### Scenario considerations\n",
    "\n",
    "* **The data was increased by 100x:** If data is to big to process in the current ETL pipeline, we could implement massive parallel processing solutions that leverage on Apache Spark in the cloud such as [AWS EMR](https://aws.amazon.com/es/emr/) or [Databricks](https://databricks.com/)\n",
    "\n",
    "* **The data populates a dashboard that must be updated on a daily basis by 7am every day.** An orchestrator solution such as [Airflow](https://airflow.apache.org/) allows to run pipelines using scheduled ETL jobs on certain time basis. It is possible to define a cron expression to run the ETL process daily at 7 am.\n",
    "\n",
    "* **The database needed to be accessed by 100+ people:** In the case a great number of people need to access the data, a Datawarehouse solution could be used to allow multiple simultaneous connections such as [AWS Redshift](https://aws.amazon.com/es/redshift/), also a [Datalakehouse](https://databricks.com/product/data-lakehouse) solution can be used to address this problem.\n",
    "\n",
    "#### Future work\n",
    "\n",
    "* Improve dimensional model including a separate Date dimension to allow more interesting date grouping.\n",
    "* Include weather and temperature dimension.\n",
    "* Implement a Datawarehouse/datalakehouse technology to improve data reading.\n",
    "* Implement data import into the datawarehouse using DBT.\n",
    "* Include an orchestrator (e.g. Airflow) to run the pipeline based on new available data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 6: ETL result demo\n",
    "\n",
    "Here is a demo of the kind of analysis that can be performed with this dimensional model. For example here we can find the number of immigrants and average age grouping by destination state, and some information regarding the origin of their last trip. Results are filtered to include only residents of Colombia (my home country). With these results we could find patterns about most visited destinations by colombians in the US and average of age of visitors. This kind of data may help to estimate a season changing origin-destination matrix by nationality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DateType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg', encoding='utf-8-sig')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "SOURCE_BUCKET = config['S3']['SOURCE_BUCKET']\n",
    "DESTINATION_BUCKET = config['S3']['DESTINATION_BUCKET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .config(\"spark.jars.packages\",\n",
    "                \"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "        .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_traveler = spark.read.parquet(\"data/out/fact_traveler\")\n",
    "dim_traveler = spark.read.parquet(\"data/out/dim_traveler\")\n",
    "dim_demography = spark.read.parquet(\"data/out/dim_demography\")\n",
    "dim_airports = spark.read.parquet(\"data/out/dim_airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_traveler.createOrReplaceTempView(\"fact_traveler\")\n",
    "dim_traveler.createOrReplaceTempView(\"dim_traveler\")\n",
    "dim_demography.createOrReplaceTempView(\"dim_demography\")\n",
    "dim_airports.createOrReplaceTempView(\"dim_airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination_state</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>origin_city</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>75.0</td>\n",
       "      <td>41.426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami International Airport</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California</td>\n",
       "      <td>NG</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>Murtala Muhammed International Airport</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>San Fernando Airport</td>\n",
       "      <td>34.0</td>\n",
       "      <td>41.852941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>Orlando Executive Airport</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Lakefront Airport</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>17.0</td>\n",
       "      <td>52.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>California</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "      <td>Houston</td>\n",
       "      <td>William P Hobby Airport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Hartsfield Jackson Atlanta International Airport</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>NG</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>Murtala Muhammed International Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>53.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>Boston</td>\n",
       "      <td>General Edward Lawrence Logan International Ai...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>43.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>US</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Lakefront Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami International Airport</td>\n",
       "      <td>7.0</td>\n",
       "      <td>54.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Florida</td>\n",
       "      <td>NG</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>Murtala Muhammed International Airport</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Dallas Love Field</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Hartsfield Jackson Atlanta International Airport</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Florida</td>\n",
       "      <td>MX</td>\n",
       "      <td>Tampico</td>\n",
       "      <td>General Francisco Javier Mina International Ai...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Seattle Tacoma International Airport</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>NG</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>Murtala Muhammed International Airport</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York</td>\n",
       "      <td>IE</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Dublin Airport</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>MG</td>\n",
       "      <td>Port BergÃƒÂ©</td>\n",
       "      <td>Port BergÃƒÂ© Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>BS</td>\n",
       "      <td>Nassau</td>\n",
       "      <td>Lynden Pindling International Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>US</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>Orlando Executive Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Coleman A. Young Municipal Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Florida</td>\n",
       "      <td>TC</td>\n",
       "      <td>None</td>\n",
       "      <td>North Caicos Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>IE</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Dublin Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Lakefront Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>Sumter Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>US</td>\n",
       "      <td>Houston</td>\n",
       "      <td>William P Hobby Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>None</td>\n",
       "      <td>IE</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Dublin Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Seattle Tacoma International Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Hartsfield Jackson Atlanta International Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>US</td>\n",
       "      <td>Kahului</td>\n",
       "      <td>Kahului Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>US</td>\n",
       "      <td>Kahului</td>\n",
       "      <td>Kahului Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "      <td>Kailua/Kona</td>\n",
       "      <td>Ellison Onizuka Kona International At Keahole ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Hartsfield Jackson Atlanta International Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>Torrington</td>\n",
       "      <td>Torrington Municipal Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>Santa Ana</td>\n",
       "      <td>John Wayne Airport-Orange County Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>Sarasota/Bradenton</td>\n",
       "      <td>Sarasota Bradenton International Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>Victorville</td>\n",
       "      <td>Southern California Logistics Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>US</td>\n",
       "      <td>Point Hope</td>\n",
       "      <td>Point Hope Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>US</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>San Fernando Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Florida</td>\n",
       "      <td>BR</td>\n",
       "      <td>ParanaÃƒÂ­ba</td>\n",
       "      <td>ParanaÃƒÂ­ba Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Houston</td>\n",
       "      <td>William P Hobby Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Texas</td>\n",
       "      <td>MX</td>\n",
       "      <td>Tampico</td>\n",
       "      <td>General Francisco Javier Mina International Ai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Salt Lake City International Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>US</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Dallas Love Field</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>Sand Point</td>\n",
       "      <td>Sand Point Airport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        destination_state origin_country         origin_city  \\\n",
       "0                New York           None                None   \n",
       "1                 Florida             US               Miami   \n",
       "2              California             NG               Lagos   \n",
       "3              California             US         Los Angeles   \n",
       "4                  Hawaii           None                None   \n",
       "5                 Florida             US             Orlando   \n",
       "6                    None           None                None   \n",
       "7                 Florida           None                None   \n",
       "8                New York             US         New Orleans   \n",
       "9                Illinois           None                None   \n",
       "10             California           None                None   \n",
       "11                  Texas             US             Houston   \n",
       "12                 Nevada           None                None   \n",
       "13                Georgia             US             Atlanta   \n",
       "14                 Nevada             NG               Lagos   \n",
       "15               Nebraska           None                None   \n",
       "16          Massachusetts             US              Boston   \n",
       "17             New Jersey             US         New Orleans   \n",
       "18               Maryland           None                None   \n",
       "19                   None             US               Miami   \n",
       "20                Florida             NG               Lagos   \n",
       "21                  Texas             US              Dallas   \n",
       "22                Florida             US             Atlanta   \n",
       "23                Florida             MX             Tampico   \n",
       "24   District of Columbia           None                None   \n",
       "25             Washington             US             Seattle   \n",
       "26                   None             NG               Lagos   \n",
       "27            Connecticut           None                None   \n",
       "28         North Carolina           None                None   \n",
       "29               New York             IE              Dublin   \n",
       "..                    ...            ...                 ...   \n",
       "184                Nevada             MG         Port BergÃƒÂ©   \n",
       "185               Georgia             BS              Nassau   \n",
       "186              Nebraska             US             Orlando   \n",
       "187             Louisiana             US             Detroit   \n",
       "188             Louisiana           None                None   \n",
       "189               Florida             TC                None   \n",
       "190              Illinois             IE              Dublin   \n",
       "191             Louisiana             US         New Orleans   \n",
       "192            California             US              Sumter   \n",
       "193              Maryland             US             Houston   \n",
       "194                  None             IE              Dublin   \n",
       "195                  None             US             Seattle   \n",
       "196                Nevada             US             Atlanta   \n",
       "197                Hawaii             US             Kahului   \n",
       "198          Pennsylvania             US             Kahului   \n",
       "199                 Texas             US         Kailua/Kona   \n",
       "200               Indiana             US             Atlanta   \n",
       "201              New York             US          Torrington   \n",
       "202                  None             US           Santa Ana   \n",
       "203                  None             US  Sarasota/Bradenton   \n",
       "204                  None             US         Victorville   \n",
       "205  District of Columbia             US          Point Hope   \n",
       "206         Massachusetts             US         Los Angeles   \n",
       "207               Florida             BR          ParanaÃƒÂ­ba   \n",
       "208            California             US             Houston   \n",
       "209                 Texas             MX             Tampico   \n",
       "210                 Idaho             US      Salt Lake City   \n",
       "211                Nevada             US              Dallas   \n",
       "212                  None             US          Sand Point   \n",
       "213              Colorado           None                None   \n",
       "\n",
       "                                        origin_airport  count    avg_age  \n",
       "0                                                 None   75.0  41.426667  \n",
       "1                          Miami International Airport   68.0  42.573529  \n",
       "2               Murtala Muhammed International Airport   49.0  40.693878  \n",
       "3                                 San Fernando Airport   34.0  41.852941  \n",
       "4                                                 None   31.0  41.548387  \n",
       "5                            Orlando Executive Airport   25.0  35.360000  \n",
       "6                                                 None   22.0  48.909091  \n",
       "7                                                 None   21.0  41.952381  \n",
       "8                                    Lakefront Airport   20.0  37.350000  \n",
       "9                                                 None   17.0  52.411765  \n",
       "10                                                None   12.0  49.416667  \n",
       "11                             William P Hobby Airport   11.0  42.818182  \n",
       "12                                                None   10.0  36.800000  \n",
       "13    Hartsfield Jackson Atlanta International Airport    9.0  59.111111  \n",
       "14              Murtala Muhammed International Airport    8.0  53.875000  \n",
       "15                                                None    8.0  36.125000  \n",
       "16   General Edward Lawrence Logan International Ai...    8.0  43.750000  \n",
       "17                                   Lakefront Airport    8.0  33.000000  \n",
       "18                                                None    8.0  49.625000  \n",
       "19                         Miami International Airport    7.0  54.714286  \n",
       "20              Murtala Muhammed International Airport    7.0  30.714286  \n",
       "21                                   Dallas Love Field    7.0  46.285714  \n",
       "22    Hartsfield Jackson Atlanta International Airport    6.0  42.166667  \n",
       "23   General Francisco Javier Mina International Ai...    6.0  52.333333  \n",
       "24                                                None    6.0  45.666667  \n",
       "25                Seattle Tacoma International Airport    6.0  58.500000  \n",
       "26              Murtala Muhammed International Airport    5.0  33.200000  \n",
       "27                                                None    5.0  59.200000  \n",
       "28                                                None    5.0  47.000000  \n",
       "29                                      Dublin Airport    5.0  34.600000  \n",
       "..                                                 ...    ...        ...  \n",
       "184                                Port BergÃƒÂ© Airport    1.0   6.000000  \n",
       "185              Lynden Pindling International Airport    1.0  21.000000  \n",
       "186                          Orlando Executive Airport    1.0  61.000000  \n",
       "187                 Coleman A. Young Municipal Airport    1.0  14.000000  \n",
       "188                                               None    1.0  16.000000  \n",
       "189                               North Caicos Airport    1.0  59.000000  \n",
       "190                                     Dublin Airport    1.0  67.000000  \n",
       "191                                  Lakefront Airport    1.0  63.000000  \n",
       "192                                     Sumter Airport    1.0  26.000000  \n",
       "193                            William P Hobby Airport    1.0  75.000000  \n",
       "194                                     Dublin Airport    1.0  52.000000  \n",
       "195               Seattle Tacoma International Airport    1.0  14.000000  \n",
       "196   Hartsfield Jackson Atlanta International Airport    1.0  56.000000  \n",
       "197                                    Kahului Airport    1.0  57.000000  \n",
       "198                                    Kahului Airport    1.0  14.000000  \n",
       "199  Ellison Onizuka Kona International At Keahole ...    1.0  24.000000  \n",
       "200   Hartsfield Jackson Atlanta International Airport    1.0  49.000000  \n",
       "201                       Torrington Municipal Airport    1.0  46.000000  \n",
       "202           John Wayne Airport-Orange County Airport    1.0  31.000000  \n",
       "203           Sarasota Bradenton International Airport    1.0  29.000000  \n",
       "204              Southern California Logistics Airport    1.0  39.000000  \n",
       "205                                 Point Hope Airport    1.0  69.000000  \n",
       "206                               San Fernando Airport    1.0  26.000000  \n",
       "207                                 ParanaÃƒÂ­ba Airport    1.0  45.000000  \n",
       "208                            William P Hobby Airport    1.0  22.000000  \n",
       "209  General Francisco Javier Mina International Ai...    1.0  39.000000  \n",
       "210               Salt Lake City International Airport    1.0  28.000000  \n",
       "211                                  Dallas Love Field    1.0  69.000000  \n",
       "212                                 Sand Point Airport    1.0  46.000000  \n",
       "213                                               None    1.0  41.000000  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT dd.state_name as destination_state,\n",
    "                 da.iso_country as origin_country,\n",
    "                 da.municipality as origin_city,\n",
    "                 da.name as origin_airport,\n",
    "                 sum(ft.count) as count,\n",
    "                 avg(ft.age) as avg_age\n",
    "          FROM fact_traveler ft\n",
    "          LEFT JOIN dim_traveler dt on ft.cicid=dt.cicid\n",
    "          LEFT JOIN (SELECT DISTINCT state_code, state_name FROM dim_demography) dd on ft.state_code=dd.state_code\n",
    "          LEFT JOIN dim_airports da on ft.iata_code=da.iata_code\n",
    "          WHERE dt.residence == 'COLOMBIA'\n",
    "          GROUP BY dd.state_name, iso_country, da.municipality, da.name\n",
    "          ORDER BY count DESC\n",
    "          \"\"\").toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
